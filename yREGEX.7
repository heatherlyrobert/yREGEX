.TH yREGEX 7 2017-nov "linux" "decision rationale, scope, and objectives"

.SH NAME
.B yREGEX
\- personal, small-volume regular-expression matching library

.SH PATRON
.B artemis-agrotera
(the huntress) goddess of the wilderness

.SH IMAGERY
beautiful young woman in cloak and deer pelt, with bow and spears

.SH SUMMARY
yREGEX is a transparent library for small-volume, day-to-day regular expression
matching based on ken thompsons finite automata algorithm (not recursion),
plus added back-references and sub-match rules.

.SH CRAZY, NIAVE, DOG-FOODING, BOOT-STRAPPING ANIMAL
i am not competing to be the best.  i created this to understand, learn,
and own every byte.  it's optimized for transparency and debugging.  if i
wanted awesome, fast, and cutting-edge, i'd use yours ;)

.SH DOCUMENTATION FILES (see also)
.nf  
yREGEX (3)         interfacing applications with library
yREGEX (6)         interactive usage and navigation
.B yREGEX (7)·········decision rationale, scope, and objectives

.SH TABLE OF CONTENTS
.nf  
a) synopsis        standard public function overview
b) overview        general overview of program
c) user-mode       detailed command line options
d) daemon-mode     detailed command line options
e) debugging       logging, debugging, and tracing

.SH BACKSTORY
.B concept.  
regular expressions are a critical computer science theory to efficently
describe, match, validate, extract, and manipulate human-language textual
patterns within larger blocks of text.

.B theory origin.  
in 1956, mathematician stephen cole kleene formalized the concept of a
regular language which could be described using his regular set notation.  all
theory at this point.

.B initial computer use.  
ken thompson was the first to migrate this concept into computer programs,
including the unix editor ed, using wicked fast, non-determinant finite
automota algorithms.

.B spread.
regex spread to vi, grep, awk, sed, emacs, databases, etc and into the posix
standard in 1992.  since the 1980's, tcl and perl have been advancing regex's
far beyond their original bounds.

.SH SCOPE, REASONING and DECISION
.B situation (S).  
there are a large number of freely available standard regular expression
libraries.  they typically implement the posix regular expression standard
plus many, many, many extensions.

.B complication (C).  
current libraries are very big, complex, opaque, optimizing affiars requiring
wild algorithms to support crazy features.  i do not wish to shackle myself
to one of these monsters.

.B solution (S).  
i will develop a variation based on efficient thompson algorithms to implement
the entire posix-extended language, plus a few hand-picked extras which will
support all my tools.

.B target user (T).  
me, just me.  i am a dogfooder and bootstrapper.

.B regular expression concerns
   -- huge volumes of duplicate, replicated, and copied text patterns
   -- parentheses for everything which eats up the capture groups
   -- backslashes are much, much too common (brutal to read)
   -- kitchen sink additions to what should have been a focused thing
   -- reportedly slow algorithms due to increased feature load
   -- recursive algorithms with potentially exponential run-times
   -- use of crazy pos/neg look-aheads to target a find string
   -- way too complex code so everyone relies on faceless maintainers
   -- summary, the mini-language, engines, and algorithms got fugly

.B what i intend to do
   -- use thompsons non-determinant finite automata algorithm
   -- add a huge amount of my standard debugging and tracing logic
   -- compile each regex first to create a wicked easy execution path
   -- support full posix extended regular expression standard (ERE)
   -- implement the 14 base metacharacters   .[]  *+?  {}  ^$  ()|  \\
   -- add short, lazy versions of *+? using the @±¢ symbols
   -- make set comparisons wicked fast since it is so common
   -- (...) become non-capuring groups rather than (?:...)
   -- (#...) become capuring groups to make them stand out
   -- (>...<) for the primary focus to avoid looks (?>=...), etc
   -- add support for pre-defined patterns, like int, byte, url, etc.
   -- (&n) support saving patterns from capture groups for reuse
   -- adjustable solution finding, i.e., first, last, longest, ...

.B what i refuse to do
   -- no optimization (that code is amazing, but crazy stuff)
   -- no unicode, international, or other encodings
   -- make a kitchen-sink solution with all the perl cruft

.B as always, all my applications must (#).  
   -- run on any linux box from raspberry to cray
   -- stay focused, small, tight, reliable, and secure
   -- focus on maintainability and debugging, not just speed
   -- forgo sloppy, kitchen-sink languages, like python, java, or perl
   -- stay away from dependency on external code libraries, like boost
   -- only human-readable, 8-bit safe, ascii streams (not database)
   -- have dedicated, maintained, automated unit testing
   -- provide either detailed reporting or logging for debugging
   -- use secure communications between systems where required
   -- clean, clean code so i can maintain after long absences
   -- use c and vim style convensions whenever possible
   -- no international, multi-lang, multi-byte support (freaking ever)
   -- all tables must be self describing with labels and queries
   -- all data structures must include dumps, reports, and audits

.SH FLAWS
.B not re-entrant,
can not be used on two regex patterns simultaneously.

.B not recursive,
so different solution orders than standard libraries.

.B named patterns
are internally compiled, and so not as flexible

.SH AUTHOR
heatherly <jelloshrke at gmail dot com>

.SH COLOPHON
this page is part of a documentation package mean to make the use of the
heatherly tools easier and faster


